# Wide 3-level model (more filters per level)

name: lfa_net
in_channels: 3
out_channels: 1

# Wide architecture: fewer levels but more filters
encoder_filters: [32, 64, 128]
bottleneck_filters: 128

# Attention parameters
dropout: 0.5
ra_k: 16
focal_gamma: 2.0
focal_alpha: 0.25

# Loss weights
bce_weight: 0.5
dice_weight: 0.5
